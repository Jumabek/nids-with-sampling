{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'pcapfile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a0dbe4784d80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpcapfile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msavefile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpcapfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinklayer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0methernet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpcapfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'pcapfile'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "from pcapfile import savefile\n",
    "from pcapfile.protocols.linklayer import ethernet\n",
    "from pcapfile.protocols.network import ip\n",
    "from pcapfile.protocols.transport import tcp\n",
    "import binascii\n",
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_record_path = '/media/mo/HDD/intrusion_detection/dataset/AttacksRecords/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processed Traffic Data\n",
    "files = ['Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv',\n",
    "        'Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv',\n",
    "        'Friday-16-02-2018_TrafficForML_CICFlowMeter.csv',\n",
    "        'Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv',\n",
    "        'Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv',\n",
    "        'Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv',\n",
    "        'Friday-23-02-2018_TrafficForML_CICFlowMeter.csv',\n",
    "        'Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv',\n",
    "        'Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv',\n",
    "        'Friday-02-03-2018_TrafficForML_CICFlowMeter.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file (file_):\n",
    "    #input the name for the CSV file\n",
    "    with open(file_, 'r') as f:\n",
    "        contents = [x.split(',') for x in f.readlines()]\n",
    "        f.flush()\n",
    "    return contents\n",
    "\n",
    "def day_attack(file_):\n",
    "    #input the content of csv file as np array\n",
    "    return [item for item in np.unique(file_[:,-1]) if item!='Benign\\n' and item!='Label\\n']\n",
    "\n",
    "def file_features(file_):\n",
    "    #input the content of csv file as np array\n",
    "    return file_[0]\n",
    "\n",
    "def extract_flowdata(file_, attack_names):\n",
    "    #input the content of csv file as np array\n",
    "    dstPort=[]\n",
    "    protocol=[]\n",
    "    #attack_records = [file_[0].tolist()]\n",
    "    attack_records = [file_[0]]\n",
    "    for name in attack_names:\n",
    "        #record=[item.tolist() for item in file_ if item[-1]==name]\n",
    "        record=[item for item in file_ if item[-1]==name]\n",
    "        attack_records.extend(record)\n",
    "        dstPort.append(np.unique(np.array(record)[:,0]).tolist())\n",
    "        protocol.append(np.unique(np.array(record)[:,1]).tolist())\n",
    "    return np.array(attack_records), dstPort, protocol\n",
    "\n",
    "def write_to_file(file_, name):\n",
    "    #input attack records\n",
    "    df = pd.DataFrame(data=file_[1:], columns=file_[0])\n",
    "    df.to_csv(name, index=False)\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_timestamp(ts):\n",
    "    return(str(datetime.utcfromtimestamp(ts)))\n",
    "\n",
    "\n",
    "def convert_datetime_timezone(dt, tz1, tz2):\n",
    "    tz1 = pytz.timezone(tz1)\n",
    "    tz2 = pytz.timezone(tz2)\n",
    "    dt = datetime.strptime(dt,\"%Y-%m-%d %H:%M:%S\")\n",
    "    dt = tz1.localize(dt)\n",
    "    dt = dt.astimezone(tz2)\n",
    "    dt = dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return dt\n",
    "\n",
    "def get_all_flows(capdata):\n",
    "    #input capdata\n",
    "    flows =[]\n",
    "    timestamps=[]\n",
    "    for pkt in capdata.packets:\n",
    "        eth_frame = ethernet.Ethernet(pkt.raw())\n",
    "        try:\n",
    "            ip_packet = ip.IP(binascii.unhexlify(eth_frame.payload))\n",
    "            tcp_packet = tcp.TCP(binascii.unhexlify(eth_frame.payload))\n",
    "        except:\n",
    "            continue\n",
    "        flows.append([ip_packet.src.decode(\"utf-8\"), ip_packet.dst.decode(\"utf-8\"), str(tcp_packet.src_port), str(tcp_packet.dst_port), str(ip_packet.p)])\n",
    "        timestamps.append(normalized_timestamp(pkt.timestamp))\n",
    "    return np.unique(flows, axis=0), flows,timestamps\n",
    "\n",
    "\n",
    "def get_attack_flows(flows, attacker_ip):\n",
    "    #input unique_flows\n",
    "    if attacker_ip in np.unique(flows[:,0]):\n",
    "        attacker_fwd_flows=[item.tolist() for item in flows if item[0]==attacker_ip]\n",
    "    else:\n",
    "        attacker_fwd_flows=[]\n",
    "        print('Attacker IP does not exist !!!')\n",
    "        \n",
    "    if attacker_ip in np.unique(flows[:,1]):\n",
    "        attacker_bwd_flows=[item.tolist() for item in flows if item[1]==attacker_ip]\n",
    "    else:\n",
    "        attacker_bwd_flows=[]\n",
    "        print('Attacker IP does not exist !!!')\n",
    "    \n",
    "    return attacker_fwd_flows, attacker_bwd_flows   \n",
    "\n",
    "\n",
    "def write_labels(attacker_fwd_flows, attacker_bwd_flows, attack):\n",
    "    uni_labeled_file = open(csv_dist_path+\"uni_labels.txt\", 'a')\n",
    "    for item in attacker_fwd_flows:\n",
    "        for initem in item:\n",
    "            uni_labeled_file.write(initem +',')\n",
    "        uni_labeled_file.write(attack)\n",
    "\n",
    "    bi_labeled_file = open(csv_dist_path+\"bi_labels.txt\", 'a')\n",
    "    for item in attacker_fwd_flows:\n",
    "        for initem in item:\n",
    "            bi_labeled_file.write(initem +',')\n",
    "        bi_labeled_file.write(attack)\n",
    "    for item in attacker_bwd_flows:\n",
    "        for initem in item:\n",
    "            bi_labeled_file.write(initem +',')\n",
    "        bi_labeled_file.write(attack)\n",
    "    uni_labeled_file.close()\n",
    "    bi_labeled_file.close()\n",
    "    \n",
    "def attack_active_time(attacker_fwd_flows,flows,timestamps):\n",
    "    for item in attacker_fwd_flows:\n",
    "        i = []\n",
    "        j = 0\n",
    "        for idx, itemx in enumerate(flows):\n",
    "            if item==itemx:\n",
    "                i.append(idx)\n",
    "                j+=1\n",
    "\n",
    "        begin_time=convert_datetime_timezone(timestamps[i[0]], \"UTC\", \"Canada/Atlantic\")\n",
    "        end_time=convert_datetime_timezone(timestamps[i[-1]], \"UTC\", \"Canada/Atlantic\")\n",
    "        print(\"Flow: {}\\n\\nBegin: {}   End: {}\\n\\nNumber of packets: {}\\n\" .format(item, begin_time,end_time,j))\n",
    "\n",
    "        \n",
    "def get_all_flows_2(cap, attackers, write_to_file):\n",
    "    #input file object and a file to write the flows in formation \n",
    "    flow_file = open (write_to_file,'a') \n",
    "    flows =[]\n",
    "    timestamps=[]\n",
    "    for pkt in savefile.load_savefile(cap, lazy=True).packets:\n",
    "        eth_frame = ethernet.Ethernet(pkt.raw())\n",
    "        try:\n",
    "            ip_packet = ip.IP(binascii.unhexlify(eth_frame.payload))\n",
    "            tcp_packet = tcp.TCP(binascii.unhexlify(eth_frame.payload))\n",
    "        except:\n",
    "            continue\n",
    "        if ip_packet.src.decode(\"utf-8\") in attackers:\n",
    "            flow_file.write('{},{},{},{},{},{}\\n'.format(ip_packet.src.decode(\"utf-8\"), ip_packet.dst.decode(\"utf-8\"), str(tcp_packet.src_port), str(tcp_packet.dst_port), str(ip_packet.p),normalized_timestamp(pkt.timestamp)))\n",
    "        else:\n",
    "            continue\n",
    "    flow_file.close()\n",
    "    \n",
    "def read_unique_flows(file_):\n",
    "    #file_ =csv_dist_path+file_\n",
    "    with open (file_,'r') as f:\n",
    "        contents = f.readlines()\n",
    "        f.flush()\n",
    "    return list(set(contents))\n",
    "\n",
    "\n",
    "\n",
    "def get_attacks_labels(unique_flows, attack_time, attack_name,labels_file): \n",
    "    flows = [item.split(',') for item in unique_flows]\n",
    "    #time = [item.split()[-1] for item in np.array(flows)[:,-1]]\n",
    "    attack_flow = open(labels_file,'a')\n",
    "    for item in flows:\n",
    "        time = item[-1].split()[-1]\n",
    "        if time > attack_time[0] and time < attack_time[1]:\n",
    "            attack_flow.write('{},{},{},{},{},{}\\n'.format(item[0],item[1],item[2],item[3],item[4],attack_name))\n",
    "    attack_flow.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_flowid(id_):\n",
    "    flowid = id_.split('-')\n",
    "    return '-'.join([flowid[1],flowid[0],flowid[3],flowid[2],flowid[4]]) \n",
    "\n",
    "def clear_labels(data):\n",
    "    for clx, item in enumerate (data):\n",
    "        if clx!=0:\n",
    "            data[clx][0] = '-'.join([item[1],item[3],item[2],item[4],item[5]])\n",
    "        if clx!=0 and item[-1] == 'No Label\\n':\n",
    "            data[clx][-1]='Benign\\n'\n",
    "        else:\n",
    "            continue\n",
    "    return data\n",
    "\n",
    "def label_flows (data, attack_source, attack_time, attack_names, save_path, infiltration=False):\n",
    "    data = np.array(data)\n",
    "    #not_flipped=True\n",
    "    for ttx, attack_name in enumerate(attack_names):\n",
    "        for source in attack_source[ttx]:\n",
    "            for idx, record in enumerate(data):\n",
    "                if idx == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    #if ttx == 0 and not_flipped:\n",
    "                    #    data[idx][0]= order_flowid(record[0])\n",
    "                    if infiltration:\n",
    "                        if record[3] == source and record[6]>=attack_time[ttx][0] and record[6]<=attack_time[ttx][1]:\n",
    "                            data[idx][-1]= attack_name+'\\n'\n",
    "                        else:\n",
    "                            continue\n",
    "                    else:\n",
    "                        if record[1] == source and record[6]>=attack_time[ttx][0] and record[6]<=attack_time[ttx][1]:\n",
    "                            data[idx][-1]= attack_name+'\\n'\n",
    "                        else:\n",
    "                            continue\n",
    "            #not_flipped=False\n",
    "    \n",
    "    data = clear_labels(data)\n",
    "    if save_path != False:\n",
    "        np.savetxt(save_path, data, delimiter=\",\", fmt='%s')\n",
    "    return data         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1: FTP-BruteForce AND SSH-Bruteforce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read processed data\n",
    "data_cicflow = read_file(csv_record_path +'Wednesday-14-02-2018/UCAP172.31.69.25_Flow.csv')\n",
    "features_cicflow = file_features(data_cicflow)\n",
    "print(\"Features:\\n {}\\n\".format(features_cicflow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_cicflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_name = ['FTP-BruteForce','SSH-Bruteforce']\n",
    "attack_source = [['18.221.219.4'], ['13.58.98.64']]\n",
    "attack_time = [['14/02/2018 09:32 AM','14/02/2018 11:09 AM'], \n",
    "               ['14/02/2018 01:01 PM','14/02/2018 02:31 PM']]\n",
    "\n",
    "data = label_flows(data_cicflow, attack_source, attack_time, attack_name,save_path=False)  \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = set(data[:,-1])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = write_to_file(data, csv_record_path+files[0])\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2: DoS-GoldenEye AND DoS-Slowloris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read processed data\n",
    "data_cicflow = read_file(csv_record_path +'Thursday-15-02-2018/UCAP172.31.69.25_Flow.csv')\n",
    "features_cicflow = file_features(data_cicflow)\n",
    "print(\"Features:\\n {}\\n Data: {}\\n\".format(features_cicflow, len(data_cicflow)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_name = ['DoS-GoldenEye','DoS-Slowloris']\n",
    "attack_source = [['18.219.211.138'], ['18.217.165.70']]\n",
    "attack_time = [['15/02/2018 08:26 AM','15/02/2018 09:09 AM'], \n",
    "               ['15/02/2018 09:59 AM','15/02/2018 10:40 AM']]\n",
    "\n",
    "data = label_flows(data_cicflow, attack_source, attack_time, attack_name,save_path=False)  \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(data[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = write_to_file(data, csv_record_path+files[1])\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3: DoS-SlowHTTPTest AND DoS-Hulk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cicflow = read_file(csv_record_path +'Friday-16-02-2018/UCAP172.31.69.25-part1.pcap_Flow.csv')\n",
    "data_cicflow += read_file(csv_record_path +'Friday-16-02-2018/UCAP172.31.69.25-part2.pcap_Flow.csv')[1:]\n",
    "\n",
    "#features_cicflow = file_features(data_cicflow)\n",
    "print(\"Features:\\n {}\\n Data: {}\\n\".format(data_cicflow[0], len(data_cicflow)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_name = ['DoS-SlowHTTPTest','DoS-Hulk']\n",
    "attack_source = [['13.59.126.31'], ['18.219.193.20']]\n",
    "attack_time = [['16/02/2018 09:12 AM','16/02/2018 10:08 AM'], \n",
    "               ['16/02/2018 12:45 PM','16/02/2018 13:19 PM']]\n",
    "\n",
    "data = label_flows(data_cicflow, attack_source, attack_time, attack_name, save_path=csv_record_path+files[2])  \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Day 4: DDoS attacks-LOIC-HTTP AND DDoS-LOIC-UDP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cicflow = read_file(csv_record_path +'Thuesday-20-02-2018/UCAP172.31.69.25_Flow.csv')\n",
    "#features_cicflow = file_features(data_cicflow)\n",
    "print(\"Features:\\n {}\\n Data: {}\\n\".format(data_cicflow[0], len(data_cicflow)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_name = ['DDoS attacks-LOIC-HTTP','DDoS-LOIC-UDP']\n",
    "attack_source = [['18.218.115.60',\n",
    "                    '18.219.9.1',\n",
    "                    '18.219.32.43',\n",
    "                    '18.218.55.126',\n",
    "                    '52.14.136.135',\n",
    "                    '18.219.5.43',\n",
    "                    '18.216.200.189',\n",
    "                    '18.218.229.235',\n",
    "                    '18.218.11.51',\n",
    "                    '18.216.24.42'], \n",
    "                 ['18.218.115.60',\n",
    "                    '18.219.9.1',\n",
    "                    '18.219.32.43',\n",
    "                    '18.218.55.126',\n",
    "                    '52.14.136.135',\n",
    "                    '18.219.5.43',\n",
    "                    '18.216.200.189',\n",
    "                    '18.218.229.235',\n",
    "                    '18.218.11.51',\n",
    "                    '18.216.24.42']]\n",
    "\n",
    "attack_time = [['20/02/2018 09:12 AM','20/02/2018 10:17 AM'], \n",
    "               ['20/02/2018 12:13 PM','20/02/2018 12:32 PM']]\n",
    "\n",
    "data = label_flows(data_cicflow, attack_source, attack_time, attack_name, save_path=False)  \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(data[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = write_to_file(data, csv_record_path+files[3])\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Day 5: DDOS attack-HOIC AND DDoS-LOIC-UDP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cicflow = read_file(csv_record_path +'Wednesday-21-02-2018/UCAP172.31.69.28 part 1_Flow.csv')\n",
    "data_cicflow+= read_file(csv_record_path +'Wednesday-21-02-2018/UCAP172.31.69.28 part 2_Flow.csv')[1:]\n",
    "\n",
    "#features_cicflow = file_features(data_cicflow)\n",
    "print(\"Features:\\n {}\\n Data: {}\\n\".format(data_cicflow[0], len(data_cicflow)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_name = ['DDOS-LOIC-UDP','DDOS-HOIC']\n",
    "attack_source = [['18.218.115.60',\n",
    "                    '18.219.9.1',\n",
    "                    '18.219.32.43',\n",
    "                    '18.218.55.126',\n",
    "                    '52.14.136.135',\n",
    "                    '18.219.5.43',\n",
    "                    '18.216.200.189',\n",
    "                    '18.218.229.235',\n",
    "                    '18.218.11.51',\n",
    "                    '18.216.24.42'], \n",
    "                 ['18.218.115.60',\n",
    "                    '18.219.9.1',\n",
    "                    '18.219.32.43',\n",
    "                    '18.218.55.126',\n",
    "                    '52.14.136.135',\n",
    "                    '18.219.5.43',\n",
    "                    '18.216.200.189',\n",
    "                    '18.218.229.235',\n",
    "                    '18.218.11.51',\n",
    "                    '18.216.24.42']]\n",
    "\n",
    "attack_time = [['21/02/2018 09:09 AM','21/02/2018 09:43 AM'], \n",
    "               ['21/02/2018 01:05 PM','21/02/2018 02:05 PM']]\n",
    "\n",
    "data = label_flows(data_cicflow, attack_source, attack_time, attack_name, save_path=False)  \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(data[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = write_to_file(data, csv_record_path+files[4])\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Day 6: Brute Force -Web AND Brute Force -XSS AND SQL Injection\n",
    "\n",
    "\n",
    "# Brute Force -Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cicflow = read_file(csv_record_path +'Thursday-22-02-2018/UCAP172.31.69.28_Flow.csv')\n",
    "\n",
    "#features_cicflow = file_features(data_cicflow)\n",
    "print(\"Features:\\n {}\\n Data: {}\\n\".format(data_cicflow[0], len(data_cicflow)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_name = ['Brute Force-Web','Brute Force-XSS','SQL Injection']\n",
    "attack_source = [['18.218.115.60'], \n",
    "                 ['18.218.115.60'],\n",
    "                 ['18.218.115.60']]\n",
    "\n",
    "attack_time = [['22/02/2018 09:17 AM','22/02/2018 10:24 AM'], \n",
    "               ['22/02/2018 01:00 PM','22/02/2018 01:29 PM'],\n",
    "               ['22/02/2018 03:15 PM','22/02/2018 03:29 PM']]\n",
    "\n",
    "data = label_flows(data_cicflow, attack_source, attack_time, attack_name, save_path=False)  \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(data[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = write_to_file(data, csv_record_path+files[5])\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Day 7: Brute Force -Web AND Brute Force -XSS AND SQL Injection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cicflow = read_file(csv_record_path +'Friday-23-02-2018/UCAP172.31.69.28_Flow.csv')\n",
    "\n",
    "#features_cicflow = file_features(data_cicflow)\n",
    "print(\"Features:\\n {}\\n Data: {}\\n\".format(data_cicflow[0], len(data_cicflow)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_name = ['Brute Force-Web','Brute Force-XSS','SQL Injection']\n",
    "attack_source = [['18.218.115.60'], \n",
    "                 ['18.218.115.60'],\n",
    "                 ['18.218.115.60']]\n",
    "\n",
    "attack_time = [['23/02/2018 09:03 AM','23/02/2018 10:03 AM'], \n",
    "               ['23/02/2018 01:00 PM','23/02/2018 02:10 PM'],\n",
    "               ['23/02/2018 02:05 PM','23/02/2018 02:18 PM']]\n",
    "\n",
    "data = label_flows(data_cicflow, attack_source, attack_time, attack_name, save_path=False)  \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(data[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = write_to_file(data, csv_record_path+files[6])\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Day 8: Infiltration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cicflow = read_file(csv_record_path +'Wednesday-28-02-2018/capEC2AMAZ-O4EL3NG-172.31.69.24- part1_Flow.csv')\n",
    "data_cicflow+= read_file(csv_record_path +'Wednesday-28-02-2018/capEC2AMAZ-O4EL3NG-172.31.69.24-part2_Flow.csv')[1:]\n",
    "\n",
    "#features_cicflow = file_features(data_cicflow)\n",
    "print(\"Features:\\n {}\\n Data: {}\\n\".format(data_cicflow[0], len(data_cicflow)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_name = ['Infiltration','Infiltration']\n",
    "attack_source = [['13.58.225.34'], \n",
    "                 ['13.58.225.34']]\n",
    "\n",
    "attack_time = [['28/02/2018 09:50 AM','28/02/2018 11:05 AM'], \n",
    "               ['28/02/2018 12:42 PM','28/02/2018 13:40 PM']]\n",
    "\n",
    "data = label_flows(data_cicflow, attack_source, attack_time, attack_name, save_path=False, infiltration=True)  \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(data[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = write_to_file(data, csv_record_path+files[7])\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Day 9: Infiltration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cicflow = read_file(csv_record_path +'Thursday-01-03-2018/capEC2AMAZ-O4EL3NG-172.31.69.13 part1_Flow.csv')\n",
    "data_cicflow+= read_file(csv_record_path +'Thursday-01-03-2018/capEC2AMAZ-O4EL3NG-172.31.69.13 part2_Flow.csv')[1:]\n",
    "data_cicflow+= read_file(csv_record_path +'Thursday-01-03-2018/capEC2AMAZ-O4EL3NG-172.31.69.13 part3_Flow.csv')[1:]\n",
    "\n",
    "#features_cicflow = file_features(data_cicflow)\n",
    "print(\"Features:\\n {}\\n Data: {}\\n\".format(data_cicflow[0], len(data_cicflow)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_name = ['Infiltration','Infiltration']\n",
    "attack_source = [['13.58.225.34'], \n",
    "                 ['13.58.225.34']]\n",
    "\n",
    "attack_time = [['01/03/2018 08:57 AM','01/03/2018 09:55 AM'], \n",
    "               ['01/03/2018 01:00 PM','01/03/2018 02:37 PM']]\n",
    "\n",
    "data = label_flows(data_cicflow, attack_source, attack_time, attack_name, save_path=False, infiltration=True)  \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(data[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = write_to_file(data, csv_record_path+files[8])\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Day 10: Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cicflow = read_file(csv_record_path +'Friday-02-03-2018/capEC2AMAZ-O4EL3NG-172.31.69.6_Flow.csv')\n",
    "data_cicflow+= read_file(csv_record_path +'Friday-02-03-2018/capEC2AMAZ-O4EL3NG-172.31.69.8_Flow.csv')[1:]\n",
    "data_cicflow+= read_file(csv_record_path +'Friday-02-03-2018/capEC2AMAZ-O4EL3NG-172.31.69.10_Flow.csv')[1:]\n",
    "data_cicflow+= read_file(csv_record_path +'Friday-02-03-2018/capEC2AMAZ-O4EL3NG-172.31.69.12_Flow.csv')[1:]\n",
    "data_cicflow+= read_file(csv_record_path +'Friday-02-03-2018/capEC2AMAZ-O4EL3NG-172.31.69.14_Flow.csv')[1:]\n",
    "data_cicflow+= read_file(csv_record_path +'Friday-02-03-2018/capEC2AMAZ-O4EL3NG-172.31.69.17_Flow.csv')[1:]\n",
    "data_cicflow+= read_file(csv_record_path +'Friday-02-03-2018/capEC2AMAZ-O4EL3NG-172.31.69.23_Flow.csv')[1:]\n",
    "data_cicflow+= read_file(csv_record_path +'Friday-02-03-2018/capEC2AMAZ-O4EL3NG-172.31.69.26_Flow.csv')[1:]\n",
    "data_cicflow+= read_file(csv_record_path +'Friday-02-03-2018/capEC2AMAZ-O4EL3NG-172.31.69.29_Flow.csv')[1:]\n",
    "data_cicflow+= read_file(csv_record_path +'Friday-02-03-2018/capEC2AMAZ-O4EL3NG-172.31.69.30_Flow.csv')[1:]\n",
    "\n",
    "\n",
    "#features_cicflow = file_features(data_cicflow)\n",
    "print(\"Features:\\n {}\\n Data: {}\\n\".format(data_cicflow[0], len(data_cicflow)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_name = ['Bot']\n",
    "attack_source = [['18.219.211.138']]\n",
    "\n",
    "attack_time = [['02/03/2018 09:11 AM','02/03/2018 10:34 AM'], \n",
    "               ['02/03/2018 01:24 PM','02/03/2018 02:55 PM']]\n",
    "\n",
    "data = label_flows(data_cicflow, attack_source, attack_time, attack_name, save_path=False)  \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(data[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = write_to_file(data, csv_record_path+files[9])\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
